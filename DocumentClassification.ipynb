{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Text pre-processing and exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from os import listdir\n",
    "from os.path import isfile, join    \n",
    "import sklearn.datasets as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you should put the directory path\n",
    "path='D:\\\\documents\\\\users\\\\nogahm\\\\Downloads\\\\ohsumed-first-20000-docs\\\\testCorpus'\n",
    "\n",
    "dirpath=path\n",
    "trainDirs=[]\n",
    "testDirs=[]\n",
    "trainFiles=[]\n",
    "testFiles=[]\n",
    "# for table\n",
    "Category=[]\n",
    "FileName=[]\n",
    "Path=[]\n",
    "Text=[]\n",
    "classNumOfDocs=[]\n",
    "docsInfo=[] #[fileName,cleanText,class\n",
    "\n",
    "stopWords=set(stopwords.words('english'))\n",
    "exploration_stop_words = {'.', ',', '(', ')','%',';',':'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test dirs\n",
    "trainDirs=os.listdir(dirpath+'\\\\training')\n",
    "testDirs=os.listdir(dirpath+'\\\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process\n",
    "def cleanText(text):\n",
    "    # tokenize\n",
    "    tokenized = word_tokenize(text)\n",
    "    # remove stop words\n",
    "    filtered_sentence = [w for w in tokenized if not w in stopWords]\n",
    "    filtered_sentence = [w for w in filtered_sentence if not w in exploration_stop_words]\n",
    "    # stemming\n",
    "    ps = PorterStemmer()\n",
    "    for i in range(len(filtered_sentence)):\n",
    "        filtered_sentence[i] = ps.stem(filtered_sentence[i])\n",
    "    # print(\"aaa\")\n",
    "    return \" \".join(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test dirs\n",
    "for dir in trainDirs:\n",
    "    for file in os.listdir(dirpath+'\\\\training\\\\'+dir):\n",
    "        trainFiles.append(file)\n",
    "        Category.append(dir)\n",
    "        FileName.append(file)\n",
    "        Path.append(dirpath+'\\\\training\\\\'+dir+'\\\\'+file)\n",
    "        # Open a file: fileReader\n",
    "        fileReader = open(dirpath+'\\\\training\\\\'+dir+'\\\\'+file,mode='r')\n",
    "        # read all lines at once\n",
    "        text = fileReader.read().lower()\n",
    "        # close the file\n",
    "        fileReader.close()\n",
    "\n",
    "        cleanedText=cleanText(text)\n",
    "        docsInfo.append([file,cleanedText,dir])\n",
    "\n",
    "for dir in testDirs:\n",
    "    for file in os.listdir(dirpath+'\\\\test\\\\'+dir):\n",
    "        testFiles.append(file)\n",
    "        Category.append(dir)\n",
    "        FileName.append(file)\n",
    "        Path.append(dirpath+'\\\\test\\\\'+dir+'\\\\'+file)\n",
    "        # Open a file: fileReader\n",
    "        fileReader = open(dirpath+'\\\\test\\\\'+dir+'\\\\'+file,mode='r')\n",
    "        # read all lines at once\n",
    "        text = fileReader.read().lower()\n",
    "        # close the file\n",
    "        fileReader.close()\n",
    "\n",
    "        cleanedText = cleanText(text)\n",
    "        docsInfo.append([file, cleanedText, dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of categories:  4\n  Class  #OfFiles\n0   C01       929\n1   C02       391\n2   C03       135\n3   C04      2630\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>term 1</th>\n",
       "      <th>term 2</th>\n",
       "      <th>term 3</th>\n",
       "      <th>term 4</th>\n",
       "      <th>term 5</th>\n",
       "      <th>term 6</th>\n",
       "      <th>term 7</th>\n",
       "      <th>term 8</th>\n",
       "      <th>term 9</th>\n",
       "      <th>term 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C01</td>\n",
       "      <td>(patient, 2145)</td>\n",
       "      <td>(infect, 1457)</td>\n",
       "      <td>(case, 551)</td>\n",
       "      <td>(group, 524)</td>\n",
       "      <td>(diseas, 516)</td>\n",
       "      <td>(studi, 513)</td>\n",
       "      <td>(treatment, 494)</td>\n",
       "      <td>(use, 464)</td>\n",
       "      <td>(less, 407)</td>\n",
       "      <td>(clinic, 407)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C02</td>\n",
       "      <td>(patient, 794)</td>\n",
       "      <td>(infect, 765)</td>\n",
       "      <td>(viru, 457)</td>\n",
       "      <td>(human, 348)</td>\n",
       "      <td>(hiv, 285)</td>\n",
       "      <td>(cell, 278)</td>\n",
       "      <td>(studi, 273)</td>\n",
       "      <td>(immunodefici, 264)</td>\n",
       "      <td>(diseas, 243)</td>\n",
       "      <td>(case, 240)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C03</td>\n",
       "      <td>(infect, 193)</td>\n",
       "      <td>(patient, 188)</td>\n",
       "      <td>(malaria, 118)</td>\n",
       "      <td>(antibodi, 84)</td>\n",
       "      <td>(case, 81)</td>\n",
       "      <td>(parasit, 80)</td>\n",
       "      <td>(respons, 73)</td>\n",
       "      <td>(studi, 73)</td>\n",
       "      <td>(day, 72)</td>\n",
       "      <td>(treatment, 72)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C04</td>\n",
       "      <td>(patient, 6719)</td>\n",
       "      <td>(cell, 3681)</td>\n",
       "      <td>(tumor, 3340)</td>\n",
       "      <td>(cancer, 2452)</td>\n",
       "      <td>(carcinoma, 1957)</td>\n",
       "      <td>(case, 1658)</td>\n",
       "      <td>(studi, 1655)</td>\n",
       "      <td>(use, 1493)</td>\n",
       "      <td>(treatment, 1308)</td>\n",
       "      <td>(diseas, 1270)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>term 1</th>\n",
       "      <th>term 2</th>\n",
       "      <th>term 3</th>\n",
       "      <th>term 4</th>\n",
       "      <th>term 5</th>\n",
       "      <th>term 6</th>\n",
       "      <th>term 7</th>\n",
       "      <th>term 8</th>\n",
       "      <th>term 9</th>\n",
       "      <th>term 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C01</td>\n",
       "      <td>(patient, 2145)</td>\n",
       "      <td>(infect, 1457)</td>\n",
       "      <td>(case, 551)</td>\n",
       "      <td>(group, 524)</td>\n",
       "      <td>(diseas, 516)</td>\n",
       "      <td>(studi, 513)</td>\n",
       "      <td>(treatment, 494)</td>\n",
       "      <td>(use, 464)</td>\n",
       "      <td>(less, 407)</td>\n",
       "      <td>(clinic, 407)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C02</td>\n",
       "      <td>(patient, 794)</td>\n",
       "      <td>(infect, 765)</td>\n",
       "      <td>(viru, 457)</td>\n",
       "      <td>(human, 348)</td>\n",
       "      <td>(hiv, 285)</td>\n",
       "      <td>(cell, 278)</td>\n",
       "      <td>(studi, 273)</td>\n",
       "      <td>(immunodefici, 264)</td>\n",
       "      <td>(diseas, 243)</td>\n",
       "      <td>(case, 240)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C03</td>\n",
       "      <td>(infect, 193)</td>\n",
       "      <td>(patient, 188)</td>\n",
       "      <td>(malaria, 118)</td>\n",
       "      <td>(antibodi, 84)</td>\n",
       "      <td>(case, 81)</td>\n",
       "      <td>(parasit, 80)</td>\n",
       "      <td>(respons, 73)</td>\n",
       "      <td>(studi, 73)</td>\n",
       "      <td>(day, 72)</td>\n",
       "      <td>(treatment, 72)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C04</td>\n",
       "      <td>(patient, 6719)</td>\n",
       "      <td>(cell, 3681)</td>\n",
       "      <td>(tumor, 3340)</td>\n",
       "      <td>(cancer, 2452)</td>\n",
       "      <td>(carcinoma, 1957)</td>\n",
       "      <td>(case, 1658)</td>\n",
       "      <td>(studi, 1655)</td>\n",
       "      <td>(use, 1493)</td>\n",
       "      <td>(treatment, 1308)</td>\n",
       "      <td>(diseas, 1270)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get number of classes and number of docs for each class\n",
    "docInfoDF=pd.DataFrame(docsInfo, columns=['fileName','cleanText','class'])\n",
    "allClasses=np.unique(docInfoDF['class'])\n",
    "print ('# of categories: ',allClasses.size)\n",
    "numOfFiles=[]\n",
    "words_per_class = []\n",
    "termsFreqPerClass=[]\n",
    "for currClass in allClasses:\n",
    "    temp=(docInfoDF['class']).value_counts()[currClass]\n",
    "    numOfFiles.append([currClass, temp])\n",
    "    #get terms distibution\n",
    "    currFiles=docInfoDF.loc[docInfoDF['class']==currClass]\n",
    "    termsFreq=pd.Series(\" \".join(currFiles['cleanText']).split()).value_counts()[:10]\n",
    "    # termsFreqPerClass.append([currClass,zip(termsFreq.index,termsFreq)])\n",
    "    zipedFreq=zip(termsFreq.index, termsFreq)\n",
    "    zippedList=list(zipedFreq)\n",
    "    termsFreqPerClass.append([currClass]+zippedList)\n",
    "\n",
    "# print number of files prt category\n",
    "numOfFilesDF=pd.DataFrame(numOfFiles,columns=['Class','#OfFiles'])\n",
    "print(numOfFilesDF)\n",
    "# print terms frequency\n",
    "pd.DataFrame(termsFreqPerClass, columns=['Class','term 1','term 2','term 3','term 4','term 5','term 6','term 7','term 8','term 9','term 10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
